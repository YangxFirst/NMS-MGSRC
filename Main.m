function [Xun_Means,Xun_Stds] = Main(dataset)
dataset_name = dataset;
load(dataset);
addpath(genpath('.'));

starttime = datestr(now,0); 
%% Model Parameters
modelparameter.round              = 5;

%% Optimization Parameters
alphas = 0.01;
lambda1s = 1000; 
betas = 0.0001;
gammas = 0.001;
lambda2s = 0.0001; 


optmParameter.sigma   = 5; % {0.1, 1, 10} % initialization
optmParameter.miu = 0.5;

optmParameter.maxIter           = 100;%最大迭代次数
optmParameter.minimumLossMargin = 0.001;%两次迭代的最小损失间距 0.0001
optmParameter.bQuiet            = 1;

labeled_rate = 0.7; % 0.7, 0.5, 0.2
%% Label Propagation Parameters
LPparam.lambda_l = 0;
LPparam.lambda_u = 0.99;
LPparam.K = 10;

%% Importing Data
if exist('train_data','var')==1
    data=[train_data;test_data];
    target=[train_target';test_target'];
    clear train_data test_data train_target test_taget
end
if exist('dataset','var')==1
    data = dataset;
    target = labels;
    clear dataset label
end

target = double(target>0);
num_data = size(data,1);

num_test = ceil(num_data*0.3);
num_train = num_data - num_test;
num_label = ceil(num_train*labeled_rate);
Result_NEW  = zeros(6,50);

beta_num = length(betas);
alpha_num = length(alphas);
gamma_num = length(gammas);
lambda1_num = length(lambda1s);
lambda2_num = length(lambda2s);
Para_num =  beta_num * alpha_num * gamma_num *lambda1_num * lambda2_num;
Avg_Means = zeros(6,Para_num);
Avg_Stds = zeros(6,Para_num);
Xun_Means = zeros( 6,Para_num);
Xun_Stds = zeros( 6,Para_num);

a  = 0;
l1 = 0;
b  = 0;
g  = 0;
l2 = 0;
k  = 1;
j  = 1;
m  = 1;
n = 1;


for alpha = alphas
    optmParameter.alpha = alpha;
    a = a + 1;
    for lambda1 = lambda1s
        optmParameter.lambda1 = lambda1;
        l1 = l1 + 1;
        for beta = betas
            optmParameter.beta = beta;
            b = b + 1;
            for gamma = gammas
                optmParameter.gamma = gamma;
                g = g +1;
                for lambda2 = lambda2s
                    optmParameter.lambda2 = lambda2;
                    l2 = l2 +1;
                    while (m <= modelparameter.round)
                        fprintf('NMS_MGSRC Running %s alpha - %d/%d lambda1 - %d/%d beta - %d/%d gamma - %d/%d lambda2 - %d/%d \n',dataset_name,a,alpha_num,l1,lambda1_num,b,beta_num,g,gamma_num,l2,lambda2_num);
                        %% the training and test parts are generated by fixed spliting with the given random order
                        randorder = randperm(num_data);
                        train_index = randorder(1:num_train);
                        test_index = randorder(num_train + 1:num_data);
                        randorder = train_index(randperm(num_train));
                        label_index = randorder(1:num_label);
                        unlabel_index = randorder((num_label+1):num_train);
                        
                        label_data = data(label_index,:); % 有标记训练样本
                        label_target = target(:,label_index); % 有标记训练样本的标签
                        unlabel_data = data(unlabel_index,:); % 无标记训练样本
                        test_data = data(test_index,:); % 测试样本
                        test_target = target(:,test_index); % 测试样本的标签
            
                        % train_data = [label_data;unlabel_data];
            
            
                        %% Training
                        [W,M]  = NMS_MGSRC(label_data,unlabel_data,label_target,LPparam,optmParameter);
                        
                        [~, feature_idx] = sort(sum(W+M,2),'descend');
                        
                        MLKNN_train_data = label_data;
                        MLKNN_test_data = test_data;
                        MLKNN_train_label = label_target;       
                        MLKNN_test_label = test_target;
                        MLKNN_train_label(MLKNN_train_label == 0) = -1;
                        MLKNN_test_label(MLKNN_test_label == 0) = -1;
                        %% Begin MLKNN
                        Num=10;
                        Smooth=1;
                        [~,num_feature]=size(MLKNN_train_data);
                        for i = 1:50
                            fprintf('Running the program with the selected features - %d/%d \n',i,num_feature);
                            f=feature_idx(1:i);
                            [Prior,PriorN,Cond,CondN]=MLKNN_train(MLKNN_train_data(:,f),MLKNN_train_label,Num,Smooth); % Invoking the training procedure
                            [Outputs,Pre_Labels]=MLKNN_test(MLKNN_train_data(:,f),MLKNN_train_label,MLKNN_test_data(:,f),MLKNN_test_label,Num,Prior,PriorN,Cond,CondN);
                            %% Evaluation of NEW
                            Result_NEW(:,i) = EvaluationAll(Pre_Labels,Outputs,MLKNN_test_label);%参数均为转置
                        end
                         if sum(isnan(Result_NEW(:,j))) == 0
                            j = j + 1;
                         end
                         %% the average results
                        Avg_Means(1:6,k) = mean(Result_NEW,2);%平均值 2代表行
                        Avg_Stds(1:6,k) = std(Result_NEW,1,2);%标准差
                        
                        X_Means(:,k) = Avg_Means(1:6,k);
                        X_Stds(:,k)  = Avg_Stds(1:6,k);
                        k = k + 1;
                        m = m + 1;
                    end
                    m = 1;
                    Xun_Means(1:6,n) = mean(X_Means,2);
                    Xun_Stds(1:6,n)  = std(X_Stds,1,2);
                    Xun_Means(7,n) = alpha;
                    Xun_Means(8,n) = lambda1;
                    Xun_Means(9,n) = beta;
                    Xun_Means(10,n) = gamma; 
                    Xun_Means(11,n) = lambda2; 
                    n = n+1;
                    j = 1;
                end
                l2 = 0;
            end
            g = 0;
        end
        b = 0;
    end
    l1 = 0;
end

Xun_Means = Xun_Means';
Xun_Stds = Xun_Stds';

end